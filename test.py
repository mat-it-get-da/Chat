from smolagents import LiteLLMModel
import dotenv
import os

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
dotenv.load_dotenv(override=True)

# API í‚¤ í™•ì¸
api_key = os.environ.get("OPENAI_API_KEY")
print(f"API í‚¤ í™•ì¸: {api_key[:10] if api_key else 'None'}...")
print(f"API í‚¤ ê¸¸ì´: {len(api_key) if api_key else 0}")

if not api_key:
    print("âŒ API í‚¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    exit()

messages = [{"role": "system", "content": "Hollw World!ë¥¼ íŒŒì´ì¬ ì½”ë“œë¡œ ì‘ì„±"}]
# GPT-4o
model_gpt_4o = LiteLLMModel(
    model_id="openai/gpt-4o",
    temperature=0.2,
    api_key=os.environ["OPENAI_API_KEY"],
    api_base="https://api.openai.com/v1",
)
# Qwen3
model_qwen3 = LiteLLMModel(
    model_id="fireworks_ai/qwen3-30b-a3b",
    temperature=0.2,
    requests_per_minute=60,
    base_url="https://api.fireworks.ai/inference/v1",
    api_key=os.environ["FIREWORKS_API_KEY"],
)
# Qwen2.5
model_qwen2p5 = LiteLLMModel(
    model_id="fireworks_ai/qwen2p5-vl-32b-instruct",
    temperature=0.2,
    requests_per_minute=60,
    base_url="https://api.fireworks.ai/inference/v1",
    api_key=os.environ["FIREWORKS_API_KEY"],
)
# Llama4
model_llama4 = LiteLLMModel(
    model_id="fireworks_ai/llama4-maverick-instruct-basic",
    temperature=0.2,
    requests_per_minute=60,
    base_url="https://api.fireworks.ai/inference/v1",
    api_key=os.environ["FIREWORKS_API_KEY"],
)
# ëª¨ë“  ë‚´ìš©ì„ ì¶œë ¥  ì˜ˆì‹œì¶œë ¥) role='assistant', annotations=[]...
# print(model(messages))
# ì»¨í…ì¸ ë§Œ ì¶œë ¥
response = model_llama4(messages)
print("ğŸ¤– ì‘ë‹µ:", response.content)
